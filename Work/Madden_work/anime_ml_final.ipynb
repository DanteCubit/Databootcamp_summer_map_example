{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import random\n",
    "\n",
    "# Pre-Processing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Models\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11903, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>episodes</th>\n",
       "      <th>rating</th>\n",
       "      <th>members</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Dementia</th>\n",
       "      <th>Demons</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Game</th>\n",
       "      <th>Historical</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Josei</th>\n",
       "      <th>Kids</th>\n",
       "      <th>Magic</th>\n",
       "      <th>MartialArts</th>\n",
       "      <th>Mecha</th>\n",
       "      <th>Military</th>\n",
       "      <th>Music</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Parody</th>\n",
       "      <th>Police</th>\n",
       "      <th>Psychological</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Samurai</th>\n",
       "      <th>School</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Seinen</th>\n",
       "      <th>Shoujo</th>\n",
       "      <th>ShoujoAi</th>\n",
       "      <th>Shounen</th>\n",
       "      <th>ShounenAi</th>\n",
       "      <th>SliceofLife</th>\n",
       "      <th>Space</th>\n",
       "      <th>Sports</th>\n",
       "      <th>SuperPower</th>\n",
       "      <th>Supernatural</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Vampire</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Music.1</th>\n",
       "      <th>ONA</th>\n",
       "      <th>OVA</th>\n",
       "      <th>Special</th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32281</td>\n",
       "      <td>Kimi no Na wa.</td>\n",
       "      <td>1</td>\n",
       "      <td>9.37</td>\n",
       "      <td>200630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5114</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>64</td>\n",
       "      <td>9.26</td>\n",
       "      <td>793665</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28977</td>\n",
       "      <td>Gintama</td>\n",
       "      <td>51</td>\n",
       "      <td>9.25</td>\n",
       "      <td>114262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9253</td>\n",
       "      <td>Steins Gate</td>\n",
       "      <td>24</td>\n",
       "      <td>9.17</td>\n",
       "      <td>673572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9969</td>\n",
       "      <td>Gintama'</td>\n",
       "      <td>51</td>\n",
       "      <td>9.16</td>\n",
       "      <td>151266</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                              name  episodes  rating  members  \\\n",
       "0     32281                    Kimi no Na wa.         1    9.37   200630   \n",
       "1      5114  Fullmetal Alchemist: Brotherhood        64    9.26   793665   \n",
       "2     28977                          Gintama         51    9.25   114262   \n",
       "3      9253                       Steins Gate        24    9.17   673572   \n",
       "4      9969                          Gintama'        51    9.16   151266   \n",
       "\n",
       "   Action  Adventure  Cars  Comedy  Dementia  Demons  Drama  Fantasy  Game  \\\n",
       "0       0          0     0       0         0       0      1        0     0   \n",
       "1       1          1     0       0         0       0      1        1     0   \n",
       "2       1          0     0       1         0       0      0        0     0   \n",
       "3       0          0     0       0         0       0      0        0     0   \n",
       "4       1          0     0       1         0       0      0        0     0   \n",
       "\n",
       "   Historical  Horror  Josei  Kids  Magic  MartialArts  Mecha  Military  \\\n",
       "0           0       0      0     0      0            0      0         0   \n",
       "1           0       0      0     0      1            0      0         1   \n",
       "2           1       0      0     0      0            0      0         0   \n",
       "3           0       0      0     0      0            0      0         0   \n",
       "4           1       0      0     0      0            0      0         0   \n",
       "\n",
       "   Music  Mystery  Parody  Police  Psychological  Romance  Samurai  School  \\\n",
       "0      0        0       0       0              0        1        0       1   \n",
       "1      0        0       0       0              0        0        0       0   \n",
       "2      0        0       1       0              0        0        1       0   \n",
       "3      0        0       0       0              0        0        0       0   \n",
       "4      0        0       1       0              0        0        1       0   \n",
       "\n",
       "   Sci-Fi  Seinen  Shoujo  ShoujoAi  Shounen  ShounenAi  SliceofLife  Space  \\\n",
       "0       0       0       0         0        0          0            0      0   \n",
       "1       0       0       0         0        1          0            0      0   \n",
       "2       1       0       0         0        1          0            0      0   \n",
       "3       1       0       0         0        0          0            0      0   \n",
       "4       1       0       0         0        1          0            0      0   \n",
       "\n",
       "   Sports  SuperPower  Supernatural  Thriller  Vampire  Movie  Music.1  ONA  \\\n",
       "0       0           0             1         0        0      1        0    0   \n",
       "1       0           0             0         0        0      0        0    0   \n",
       "2       0           0             0         0        0      0        0    0   \n",
       "3       0           0             0         1        0      0        0    0   \n",
       "4       0           0             0         0        0      0        0    0   \n",
       "\n",
       "   OVA  Special  TV  \n",
       "0    0        0   0  \n",
       "1    0        0   1  \n",
       "2    0        0   1  \n",
       "3    0        0   1  \n",
       "4    0        0   1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"anime_ml.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(self, anime_name=None, genres=None, type_filter=None, rating_min=None, episodes_min=None):\n",
    "    # Filter DataFrame based on user input\n",
    "    filtered_df = self.df.copy()\n",
    "\n",
    "    # Filter by anime name\n",
    "    if anime_name:\n",
    "        anime_match = filtered_df[filtered_df['name'] == anime_name]\n",
    "        if anime_match.empty:\n",
    "            raise ValueError(f\"Anime '{anime_name}' not found.\")\n",
    "        anime_id = anime_match['anime_id'].values[0]\n",
    "    else:\n",
    "        # Randomly select an anime if no name is provided\n",
    "        if filtered_df.empty:\n",
    "            raise ValueError(\"No anime data available.\")\n",
    "        anime_id = random.choice(filtered_df['anime_id'].values)\n",
    "\n",
    "    # Apply genre filter if specified\n",
    "    if genres:\n",
    "        genre_filter = filtered_df[genres].sum(axis=1) > 0  # Keep rows where at least one genre is present\n",
    "        filtered_df = filtered_df[genre_filter]\n",
    "\n",
    "    # Apply type filter if specified\n",
    "    if type_filter:\n",
    "        type_conditions = [filtered_df[type] == True for type in type_filter if type in filtered_df.columns]\n",
    "        if type_conditions:\n",
    "            combined_condition = np.logical_or.reduce(type_conditions)\n",
    "            filtered_df = filtered_df[combined_condition]\n",
    "\n",
    "    # Apply minimum rating filter if specified\n",
    "    if rating_min is not None:\n",
    "        filtered_df = filtered_df[filtered_df['rating'] >= rating_min]\n",
    "\n",
    "    # Apply minimum episodes filter if specified\n",
    "    if episodes_min is not None:\n",
    "        filtered_df = filtered_df[filtered_df['episodes'] >= episodes_min]\n",
    "\n",
    "    # If no anime matches the filters, raise an error\n",
    "    if filtered_df.empty:\n",
    "        raise ValueError(\"No anime found for the specified filters.\")\n",
    "\n",
    "    # Prepare the feature matrix for the Nearest Neighbors model\n",
    "    feature_cols = ['episodes', 'rating', 'members']  # Add more as needed\n",
    "    X = filtered_df[feature_cols]\n",
    "    X_preprocessed = self.preprocessor.transform(X)\n",
    "\n",
    "    # Extract features of the selected anime\n",
    "    anime_features = self.df.loc[self.df['anime_id'] == anime_id, feature_cols]\n",
    "\n",
    "    # Check if the selected anime exists in the original DataFrame after filtering\n",
    "    if anime_features.empty:\n",
    "        raise ValueError(f\"Selected anime ID '{anime_id}' is not present in the original DataFrame after filtering.\")\n",
    "\n",
    "    anime_features_preprocessed = self.preprocessor.transform(anime_features)\n",
    "\n",
    "    # Find the nearest neighbors\n",
    "    distances, indices = self.model.kneighbors(anime_features_preprocessed)\n",
    "\n",
    "    # Retrieve the metadata of the recommended animes\n",
    "    recommendations = filtered_df.iloc[indices[0]].copy()\n",
    "    recommendations[\"distance\"] = distances[0]  # Add distances to the DataFrame\n",
    "\n",
    "    # Sort by distance and return\n",
    "    recommendations = recommendations.sort_values(by=\"distance\")\n",
    "    return recommendations.to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fit(anime_length): \n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"anime_ml.csv\")\n",
    "\n",
    "    # Remove any rows with missing values and reset the index\n",
    "    df = df.dropna(how=\"any\").reset_index(drop=True)\n",
    "\n",
    "    # Update the column name if necessary\n",
    "    df.rename(columns={'Music.1': 'Music'}, inplace=True)\n",
    "\n",
    "    # Remove duplicate anime based on name\n",
    "    df = df.drop_duplicates(subset=[\"name\"]).reset_index(drop=True)\n",
    "\n",
    "    # Define the columns for metadata and features\n",
    "    meta_cols = [\"anime_id\", \"name\"]\n",
    "    feature_cols = ['episodes', 'rating', 'members'] + (genres if genres else [])  # Include genres if provided\n",
    "\n",
    "    # Preprocessing for numeric features\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Combine all preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, ['episodes', 'rating', 'members'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Determine which anime to base recommendations on\n",
    "    if anime_name:\n",
    "        anime_match = df.loc[df.name == anime_name]\n",
    "        if anime_match.empty:\n",
    "            raise ValueError(f\"Anime '{anime_name}' not found.\")\n",
    "        anime_id = anime_match.sort_values(by=\"rating\", ascending=False).anime_id.values[0]\n",
    "    else:\n",
    "        # Randomly select an anime if no name is provided\n",
    "        anime_id = random.choice(df['anime_id'].values)\n",
    "\n",
    "    # Apply genre filter if specified\n",
    "    filtered_df = df\n",
    "    if genres is not None and genres:\n",
    "        genre_filter = filtered_df[genres].sum(axis=1) > 0  # Keep rows where at least one genre is present\n",
    "        filtered_df = filtered_df[genre_filter]\n",
    "\n",
    "    # Apply type filter if specified\n",
    "    if type_filter is not None and type_filter:\n",
    "        type_conditions = [filtered_df[type] == True for type in type_filter if type in filtered_df.columns]\n",
    "        if type_conditions:\n",
    "            combined_condition = np.logical_or.reduce(type_conditions)\n",
    "            filtered_df = filtered_df[combined_condition]\n",
    "\n",
    "    # Apply minimum rating filter if specified\n",
    "    if rating_min is not None:\n",
    "        filtered_df = filtered_df[filtered_df['rating'] >= rating_min]\n",
    "\n",
    "    # Apply minimum episodes filter if specified\n",
    "    if episodes_min is not None:\n",
    "        filtered_df = filtered_df[filtered_df['episodes'] >= episodes_min]\n",
    "\n",
    "    # If no anime matches the filters, raise an error\n",
    "    if filtered_df.empty:\n",
    "        raise ValueError(\"No anime found for the specified filters.\")\n",
    "\n",
    "    # Prepare the feature matrix for the Nearest Neighbors model\n",
    "    X = filtered_df[feature_cols]  # Select the feature columns\n",
    "    X_preprocessed = preprocessor.fit_transform(X)  # Fit and transform the feature matrix\n",
    "\n",
    "    # Initialize and fit the Nearest Neighbors model\n",
    "    k = anime_length\n",
    "    model1 = NearestNeighbors(n_neighbors=k, metric=\"cosine\")\n",
    "    model1.fit(X_preprocessed)\n",
    "\n",
    "    with open('anime_length_name.pkl', 'wb') as model_file:\n",
    "        pkl.dump(model1, model_file)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def make_recommendation(anime_model, anime_name=None, genres=None, type_filter=None, rating_min=None, episodes_min=None): \n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"anime_ml.csv\")\n",
    "\n",
    "\n",
    "    # Load Pickle file\n",
    "    filename = anime_model\n",
    "    model1 = pkl.load(open(filename, 'rb')) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Define the columns for metadata and features\n",
    "    meta_cols = [\"anime_id\", \"name\"]\n",
    "    feature_cols = ['episodes', 'rating', 'members'] + (genres if genres else [])  # Include genres if provided\n",
    "\n",
    "    # Preprocessing for numeric features\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Combine all preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, ['episodes', 'rating', 'members'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "     # Determine which anime to base recommendations on\n",
    "    if anime_name:\n",
    "        anime_match = df.loc[df.name == anime_name]\n",
    "        if anime_match.empty:\n",
    "            raise ValueError(f\"Anime '{anime_name}' not found.\")\n",
    "        anime_id = anime_match.sort_values(by=\"rating\", ascending=False).anime_id.values[0]\n",
    "    else:\n",
    "        # Randomly select an anime if no name is provided\n",
    "        anime_id = random.choice(df['anime_id'].values)\n",
    "\n",
    "    # Apply genre filter if specified\n",
    "    filtered_df = df\n",
    "    if genres is not None and genres:\n",
    "        genre_filter = filtered_df[genres].sum(axis=1) > 0  # Keep rows where at least one genre is present\n",
    "        filtered_df = filtered_df[genre_filter]\n",
    "\n",
    "    # Apply type filter if specified\n",
    "    if type_filter is not None and type_filter:\n",
    "        type_conditions = [filtered_df[type] == True for type in type_filter if type in filtered_df.columns]\n",
    "        if type_conditions:\n",
    "            combined_condition = np.logical_or.reduce(type_conditions)\n",
    "            filtered_df = filtered_df[combined_condition]\n",
    "\n",
    "    # Apply minimum rating filter if specified\n",
    "    if rating_min is not None:\n",
    "        filtered_df = filtered_df[filtered_df['rating'] >= rating_min]\n",
    "\n",
    "    # Apply minimum episodes filter if specified\n",
    "    if episodes_min is not None:\n",
    "        filtered_df = filtered_df[filtered_df['episodes'] >= episodes_min]\n",
    "\n",
    "    # If no anime matches the filters, raise an error\n",
    "    if filtered_df.empty:\n",
    "        raise ValueError(\"No anime found for the specified filters.\")\n",
    "\n",
    "\n",
    "    # Extract features of the selected anime\n",
    "    anime_features = df.loc[df.anime_id == anime_id, feature_cols]\n",
    "    anime_features_preprocessed = preprocessor.transform(anime_features)\n",
    "\n",
    "    # Find the nearest neighbors\n",
    "    distances, indices = model1.kneighbors(anime_features_preprocessed)\n",
    "\n",
    "    # Retrieve the metadata of the recommended animes\n",
    "    animes = filtered_df.iloc[indices[0]]\n",
    "    animes[\"distance\"] = distances[0]  # Add distances to the DataFrame\n",
    "\n",
    "    # Filter the columns for the final output\n",
    "    animes = animes.sort_values(by=\"distance\")  # Sort by distance\n",
    "\n",
    "    # Return the recommended animes as a list of dictionaries\n",
    "    return animes.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fit(anime_length, genres=None): \n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"anime_ml.csv\")\n",
    "\n",
    "    # Remove any rows with missing values and reset the index\n",
    "    df = df.dropna(how=\"any\").reset_index(drop=True)\n",
    "\n",
    "    # Update the column name if necessary\n",
    "    df.rename(columns={'Music.1': 'Music'}, inplace=True)\n",
    "\n",
    "    # Remove duplicate anime based on name\n",
    "    df = df.drop_duplicates(subset=[\"name\"]).reset_index(drop=True)\n",
    "\n",
    "    # Define the columns for metadata and features\n",
    "    feature_cols = ['episodes', 'rating', 'members'] + (genres if genres else [])\n",
    "\n",
    "    # Preprocessing for numeric features\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # Combine all preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, ['episodes', 'rating', 'members'])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Prepare the feature matrix\n",
    "    X = df[feature_cols]\n",
    "    X_preprocessed = preprocessor.fit_transform(X)  # Fit and transform the feature matrix\n",
    "\n",
    "    # Initialize and fit the Nearest Neighbors model\n",
    "    model1 = NearestNeighbors(n_neighbors=anime_length, metric=\"cosine\")\n",
    "    model1.fit(X_preprocessed)\n",
    "\n",
    "    # Save the model and preprocessor\n",
    "    with open('anime_model.pkl', 'wb') as model_file:\n",
    "        pkl.dump(model1, model_file)\n",
    "    with open('preprocessor.pkl', 'wb') as preprocessor_file:\n",
    "        pkl.dump(preprocessor, preprocessor_file)\n",
    "\n",
    "def make_recommendation(anime_model='anime_model.pkl', preprocessor_model='preprocessor.pkl', anime_name=None, genres=None, type_filter=None, rating_min=None, episodes_min=None): \n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"anime_ml.csv\")\n",
    "\n",
    "    # Load Pickle files\n",
    "    model1 = pkl.load(open(anime_model, 'rb')) \n",
    "    preprocessor = pkl.load(open(preprocessor_model, 'rb'))\n",
    "\n",
    "    # Define the columns for metadata and features\n",
    "    feature_cols = ['episodes', 'rating', 'members'] + (genres if genres else [])\n",
    "\n",
    "    # Determine which anime to base recommendations on\n",
    "    if anime_name:\n",
    "        anime_match = df.loc[df.name == anime_name]\n",
    "        if anime_match.empty:\n",
    "            raise ValueError(f\"Anime '{anime_name}' not found.\")\n",
    "        anime_id = anime_match.sort_values(by=\"rating\", ascending=False).anime_id.values[0]\n",
    "    else:\n",
    "        # Randomly select an anime if no name is provided\n",
    "        anime_id = random.choice(df['anime_id'].values)\n",
    "\n",
    "    # Apply genre filter if specified\n",
    "    filtered_df = df\n",
    "    if genres is not None and genres:\n",
    "        genre_filter = filtered_df[genres].any(axis=1)  # Keep rows where at least one genre is True\n",
    "        filtered_df = filtered_df[genre_filter]\n",
    "\n",
    "    # Apply type filter if specified\n",
    "    if type_filter is not None and type_filter:\n",
    "        type_conditions = [filtered_df[type] for type in type_filter if type in filtered_df.columns]\n",
    "        if type_conditions:\n",
    "            combined_condition = np.logical_or.reduce(type_conditions)\n",
    "            filtered_df = filtered_df[combined_condition]\n",
    "\n",
    "    # Apply minimum rating filter if specified\n",
    "    if rating_min is not None:\n",
    "        filtered_df = filtered_df[filtered_df['rating'] >= rating_min]\n",
    "\n",
    "    # Apply minimum episodes filter if specified\n",
    "    if episodes_min is not None:\n",
    "        filtered_df = filtered_df[filtered_df['episodes'] >= episodes_min]\n",
    "\n",
    "    # If no anime matches the filters, raise an error\n",
    "    if filtered_df.empty:\n",
    "        raise ValueError(\"No anime found for the specified filters.\")\n",
    "\n",
    "    # Extract features of the selected anime\n",
    "    anime_features = df.loc[df.anime_id == anime_id, feature_cols]\n",
    "    anime_features_preprocessed = preprocessor.transform(anime_features)\n",
    "\n",
    "    # Find the nearest neighbors\n",
    "    distances, indices = model1.kneighbors(anime_features_preprocessed)\n",
    "\n",
    "    print(indices[0])\n",
    "   # Retrieve the metadata of the recommended animes\n",
    "    animes = filtered_df.iloc[indices[0]]\n",
    "    animes[\"distance\"] = distances[0]  # Add distances to the DataFrame\n",
    "\n",
    "    # Filter the columns for the final output\n",
    "    animes = animes.sort_values(by=\"distance\")  # Sort by distance\n",
    "\n",
    "    # Return the recommended animes as a list of dictionaries\n",
    "    return animes.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_fit(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5524  5533  5530  9145  5503  5477  9912 10535  5471  8453  5577 10401\n",
      "  5431  5482  5505  8736 10602 10452 10355  5664]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexing.py:1676\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1675\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda\\envs\\dev\\lib\\site-packages\\pandas\\core\\generic.py:4088\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4079\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4080\u001b[0m \u001b[38;5;124;03mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4081\u001b[0m \u001b[38;5;124;03mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4086\u001b[0m \u001b[38;5;124;03mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4087\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4088\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4089\u001b[0m \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda\\envs\\dev\\lib\\site-packages\\pandas\\core\\generic.py:4068\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4064\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4065\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4066\u001b[0m     )\n\u001b[1;32m-> 4068\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4070\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4072\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4074\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4075\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda\\envs\\dev\\lib\\site-packages\\pandas\\core\\internals\\managers.py:874\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    873\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[1;32m--> 874\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:282\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[1;34m(indices, n, verify)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[1;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m rating_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Minimum rating (can be None if no minimum is needed)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m episodes_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# Minimum episodes (can be None if no minimum is needed)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmake_recommendation\u001b[49m\u001b[43m(\u001b[49m\u001b[43manime_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manime_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrating_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrating_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisodes_min\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 99\u001b[0m, in \u001b[0;36mmake_recommendation\u001b[1;34m(anime_model, preprocessor_model, anime_name, genres, type_filter, rating_min, episodes_min)\u001b[0m\n\u001b[0;32m     97\u001b[0m  \u001b[38;5;28mprint\u001b[39m(indices[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# Retrieve the metadata of the recommended animes\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m  animes \u001b[38;5;241m=\u001b[39m \u001b[43mfiltered_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    100\u001b[0m  animes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m distances[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Add distances to the DataFrame\u001b[39;00m\n\u001b[0;32m    102\u001b[0m  \u001b[38;5;66;03m# Filter the columns for the final output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexing.py:1705\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m-> 1705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_list_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;66;03m# a single integer\u001b[39;00m\n\u001b[0;32m   1708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1709\u001b[0m     key \u001b[38;5;241m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[1;32mc:\\Users\\Public\\anaconda\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexing.py:1679\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;66;03m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[39;00m\n\u001b[1;32m-> 1679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositional indexers are out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "anime_name = None  # Can be None if no specific anime is needed\n",
    "genres = [\"Comedy\"]  # Specify the genres you want to filter by (can be None)\n",
    "type_filter = None  # Specify the types to filter by (can be None)\n",
    "rating_min = None  # Minimum rating (can be None if no minimum is needed)\n",
    "episodes_min = 100  # Minimum episodes (can be None if no minimum is needed)\n",
    "\n",
    "response = make_recommendation(anime_name=anime_name, genres=genres, type_filter=type_filter, rating_min=rating_min, episodes_min=episodes_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# To test\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mresponse\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "# To test\n",
    "pd.DataFrame(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
